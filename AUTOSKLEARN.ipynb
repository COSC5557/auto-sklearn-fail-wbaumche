{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Work around for using Autosklearn in Colab\n",
        "!pip install git+https://github.com/Frankothe196/auto-sklearn.git@python3.10-added-compatibility;"
      ],
      "metadata": {
        "id": "-Wf6MJVj-vrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012220c0-7bbb-4deb-f1f8-15d10b19b092"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Frankothe196/auto-sklearn.git@python3.10-added-compatibility\n",
            "  Cloning https://github.com/Frankothe196/auto-sklearn.git (to revision python3.10-added-compatibility) to /tmp/pip-req-build-dyvunogr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Frankothe196/auto-sklearn.git /tmp/pip-req-build-dyvunogr\n",
            "  Running command git checkout -b python3.10-added-compatibility --track origin/python3.10-added-compatibility\n",
            "  Switched to a new branch 'python3.10-added-compatibility'\n",
            "  Branch 'python3.10-added-compatibility' set up to track remote branch 'python3.10-added-compatibility' from 'origin'.\n",
            "  Resolved https://github.com/Frankothe196/auto-sklearn.git to commit 80a575760e99945fa31970b1479edeb759bc645a\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from auto-sklearn==0.16.0.dev0) (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (1.11.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (1.2.2)\n",
            "Requirement already satisfied: dask>=2021.12 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (2023.8.1)\n",
            "Requirement already satisfied: distributed>=2012.12 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (2023.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (1.5.3)\n",
            "Collecting liac-arff (from auto-sklearn==0.16.0.dev0)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-sklearn==0.16.0.dev0) (4.66.1)\n",
            "Collecting ConfigSpace<0.5,>=0.4.21 (from auto-sklearn==0.16.0.dev0)\n",
            "  Downloading ConfigSpace-0.4.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynisher<0.7,>=0.6.3 (from auto-sklearn==0.16.0.dev0)\n",
            "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyrfr<0.9,>=0.8.1 (from auto-sklearn==0.16.0.dev0)\n",
            "  Downloading pyrfr-0.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smac<1.3,>=1.2 (from auto-sklearn==0.16.0.dev0)\n",
            "  Downloading smac-1.2.tar.gz (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn==0.16.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn==0.16.0.dev0) (3.1.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn==0.16.0.dev0) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn==0.16.0.dev0) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn==0.16.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn==0.16.0.dev0) (23.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn==0.16.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn==0.16.0.dev0) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn==0.16.0.dev0) (7.0.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (1.0.7)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (6.3.2)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn==0.16.0.dev0) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn==0.16.0.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn==0.16.0.dev0) (2023.3.post1)\n",
            "Collecting emcee>=3.0.0 (from smac<1.3,>=1.2->auto-sklearn==0.16.0.dev0)\n",
            "  Downloading emcee-3.1.4-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2021.12->auto-sklearn==0.16.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2012.12->auto-sklearn==0.16.0.dev0) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0->auto-sklearn==0.16.0.dev0) (1.16.0)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher, smac, liac-arff\n",
            "  Building wheel for auto-sklearn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.16.0.dev0-py3-none-any.whl size=6847471 sha256=756c4b0b38b200e2dd6689427a13221c5e1bef5d9cbc057f30672e4b1c4ccb81\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6h1xm1rn/wheels/b2/a5/36/69585487bc52484f01b9a841fbcd250f9330709973a8f5caef\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7026 sha256=60dc3fd1687267042e5d684ed9a7b235024099563875f552f3d897dc68bc6e3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/7b/53/b21d6b41910f43c7f1557262e579598f83e75e44c659c1bcce\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-1.2-py3-none-any.whl size=215910 sha256=95b6760e415caa8c2bc8932b6953caba7837a3965aba9af697dea5cb64e5848f\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/2e/d9/2db14bdfcdc36bf12e202b44201df03f194367fcfd85ce2778\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=226d97dc66a2b9bbe1b39a9a2178e140bfcbc9f8a312f56e9a7ea873277dacbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built auto-sklearn pynisher smac liac-arff\n",
            "Installing collected packages: pyrfr, pynisher, liac-arff, emcee, ConfigSpace, smac, auto-sklearn\n",
            "Successfully installed ConfigSpace-0.4.21 auto-sklearn-0.16.0.dev0 emcee-3.1.4 liac-arff-2.5.0 pynisher-0.6.4 pyrfr-0.8.3 smac-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "from sklearn.datasets import fetch_openml\n",
        "import sklearn.metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "X, y = fetch_openml(data_id=40691, as_frame=True, return_X_y=True)\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "X = enc.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(random_state=41)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "print(\"RF Accuracy\", sklearn.metrics.accuracy_score(y_test, y_hat))\n",
        "\n",
        "# Redo using pure data, instead of one-hot encoding -- One-Hot encoding is meant\n",
        "# for use on categorical data. However, the values presented as 'observations'\n",
        "# meant to serve as predictors for the 'quality' of the wine are continous real\n",
        "# values. As such, preforming one-hot encoding is not the way to use it.\n",
        "from autosklearn.classification import AutoSklearnClassifier\n",
        "X, y = fetch_openml(data_id=40691, as_frame=True, return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=42)\n",
        "# After checking training and testing data, it was found that while the\n",
        "# training data accuracy was good, the test accuracy was bad. So to avoid\n",
        "# overfitting, trying out a different resampling strategy! As such,\n",
        "# testing cv strategy with normal 10 folds.\n",
        "# In addition; tried running with greater budget, slightly better, but not by a lot.\n",
        "\n",
        "automl = AutoSklearnClassifier(time_left_for_this_task=300,resampling_strategy='cv',resampling_strategy_arguments={\"folds\": 10})\n",
        "automl.fit(X_train, y_train)\n",
        "y_hat = automl.predict(X_test)\n",
        "print(\"AutoML Accuracy On Test\", sklearn.metrics.accuracy_score(y_test, y_hat))\n",
        "\n",
        "automl.refit(X_train,y_train)\n",
        "y_h = automl.predict(X_train)\n",
        "print(\"AutoML Accuracy on Training\", sklearn.metrics.accuracy_score(y_train, y_h))\n",
        "# Leaderboard training\n",
        "print(automl.leaderboard())\n",
        "automl.sprint_statistics()\n",
        "\n",
        "# This works, with 0.6725 accuracy on test set as opposed to previous. With\n",
        "# extended training time of 500 iterations, resulting in 0.675"
      ],
      "metadata": {
        "id": "uMYkZh2X-2XY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "e7c613e6-0fb2-4126-d45f-62244a4ff57f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Accuracy 0.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/autosklearn/data/target_validator.py:187: UserWarning: Fitting transformer with a pandas series which has the dtype category. Inverse transform may not be able preserve dtype when converting to np.ndarray\n",
            "  warnings.warn(\n",
            "Fitting to the training data: 100%|\u001b[32m██████████\u001b[0m| 300/300 [04:52<00:00,  1.02it/s, The total time budget for this task is 0:05:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML Accuracy On Test 0.6725\n",
            "AutoML Accuracy on Training 1.0\n",
            "          rank  ensemble_weight               type      cost   duration\n",
            "model_id                                                               \n",
            "2            1             0.44      random_forest  0.306922  27.785364\n",
            "4            2             0.46      random_forest  0.307756  24.112124\n",
            "9            3             0.02  gradient_boosting  0.384487  18.510952\n",
            "5            4             0.08  gradient_boosting  0.496247   8.410860\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'auto-sklearn results:\\n  Dataset name: f8e8e5dc-9471-11ee-8178-0242ac1c000c\\n  Metric: accuracy\\n  Best validation score: 0.693078\\n  Number of target algorithm runs: 13\\n  Number of successful target algorithm runs: 4\\n  Number of crashed target algorithm runs: 2\\n  Number of target algorithms that exceeded the time limit: 7\\n  Number of target algorithms that exceeded the memory limit: 0\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}